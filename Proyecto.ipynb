{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0bea67",
   "metadata": {},
   "source": [
    "# Trabajo Final AIVA: Narrador Autom√°tico de Ajedrez \n",
    "\n",
    "## Descripci√≥n del Proyecto\n",
    "Este proyecto implementa un sistema de visi√≥n artificial capaz de **analizar una partida de ajedrez en v√≠deo y narrar las jugadas en tiempo real**.\n",
    "\n",
    "El sistema utiliza **YOLOv8** para la detecci√≥n de piezas y un algoritmo l√≥gico personalizado para interpretar las reglas del ajedrez (movimientos, capturas, enroques y coronaciones), mostrando el historial de la partida en una interfaz gr√°fica superpuesta.\n",
    "\n",
    "### Autor\n",
    "* **Ra√∫l S√°nchez Ib√°√±ez**\n",
    "* Asignatura: Aplicaciones Industriales de Visi√≥n Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c0f7c",
   "metadata": {},
   "source": [
    "## 1. Generaci√≥n del Dataset: Extracci√≥n de Frames\n",
    "\n",
    "Antes de entrenar el modelo, es necesario construir un banco de im√°genes. En esta fase, procesamos los v√≠deos de partidas grabadas para convertirlos en im√°genes est√°ticas que servir√°n de base para el entrenamiento.\n",
    "\n",
    "Utilizamos la librer√≠a **OpenCV** para leer los archivos de v√≠deo y extraer fotogramas peri√≥dicamente.\n",
    "* **Estrategia:** Se guarda solo 1 frame cada 150 (variable `saltar_frames`) para garantizar variedad en las posiciones del tablero y evitar tener miles de im√°genes casi id√©nticas, lo cual podr√≠a provocar *overfitting* (sobreajuste).\n",
    "* **Salida:** Las im√°genes resultantes se almacenan en la carpeta `dataset`, listas para ser etiquetadas manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed46159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# CONFIGURACI√ìN \n",
    "# Ruta base donde estan los videos\n",
    "\n",
    "RUTA_VIDEOS = \"T05-T06_videos\"\n",
    "\n",
    "# Nombres de los videos\n",
    "VIDEOS = [\n",
    "    \"Video1.mp4\",\n",
    "    \"Video2.mp4\"\n",
    "]\n",
    "\n",
    "# Carpeta donde se guardar√°n las fotos extra√≠das\n",
    "CARPETA_SALIDA = os.path.join(RUTA_VIDEOS, \"dataset\")\n",
    "\n",
    "def extraer_frames(video_filename, saltar_frames=150):\n",
    "    video_path = os.path.join(RUTA_VIDEOS, video_filename)\n",
    "    \n",
    "    # Verificar que el archivo existe antes de intentar abrirlo\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"‚ùå NO ENCONTRADO: {video_path}\")\n",
    "        print(\"   -> Verifica si falta la letra de la unidad (ej: 'C:\\\\...') o si la ruta es correcta.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error al abrir el video: {video_filename}\")\n",
    "        return\n",
    "\n",
    "    # Crear carpeta de salida si no existe\n",
    "    if not os.path.exists(CARPETA_SALIDA):\n",
    "        os.makedirs(CARPETA_SALIDA)\n",
    "        print(f\"üìÇ Carpeta creada: {CARPETA_SALIDA}\")\n",
    "\n",
    "    count = 0\n",
    "    saved_count = 0\n",
    "    video_name_simple = os.path.splitext(video_filename)[0][:15] # Usamos un nombre corto para el archivo\n",
    "\n",
    "    print(f\"üé• Procesando: {video_filename}...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Guardamos 1 frame cada 'saltar_frames'\n",
    "        if count % saltar_frames == 0:\n",
    "            output_name = f\"{video_name_simple}_{count}.jpg\"\n",
    "            save_path = os.path.join(CARPETA_SALIDA, output_name)           \n",
    "            cv2.imwrite(save_path, frame)\n",
    "            saved_count += 1\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"‚úÖ Terminado. Se guardaron {saved_count} im√°genes de este video.\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9d89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor video in VIDEOS:\\n    extraer_frames(video, saltar_frames=150) # 150 frames ~ 5 segundos a 30fps\\nprint(f\"üöÄ LISTO. Revisa la carpeta: {CARPETA_SALIDA}\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for video in VIDEOS:\n",
    "    extraer_frames(video, saltar_frames=150) # 150 frames ~ 5 segundos a 30fps\n",
    "print(f\"üöÄ LISTO. Revisa la carpeta: {CARPETA_SALIDA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a857f4",
   "metadata": {},
   "source": [
    "## 2. Etiquetado de Datos\n",
    "\n",
    "Una vez tenemos las im√°genes \"crudas\", es necesario ense√±ar a la IA qu√© es cada cosa. Para ello, utilizamos la herramienta gr√°fica **LabelImg**.\n",
    "\n",
    "Este script lanza la aplicaci√≥n configur√°ndola autom√°ticamente para:\n",
    "1.  Abrir directamente la carpeta de im√°genes extra√≠das.\n",
    "2.  **Cargar la lista de clases predefinida (`classes.txt`):** Esto es crucial para asegurar la consistencia. Al pasar el archivo como argumento, garantizamos que el ID `0` siempre sea `p_b` (Pe√≥n Blanco), el ID `1` sea `p_n`, etc., evitando que el orden cambie entre sesiones.\n",
    "3.  Guardar las etiquetas en formato **YOLO** (archivos `.txt` con coordenadas normalizadas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42fca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando: labelImg T05-T06_videos/dataset_raw/images T05-T06_videos/dataset_raw/labels/classes.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Define d√≥nde est√°n las cosas\n",
    "carpeta_imagenes = \"T05-T06_videos/dataset_raw/images\" \n",
    "archivo_clases = \"T05-T06_videos/dataset_raw/labels/classes.txt\"                 \n",
    "\n",
    "# Esto lanza el programa pas√°ndole el archivo de clases como argumento\n",
    "comando = f\"labelImg {carpeta_imagenes} {archivo_clases}\"\n",
    "\n",
    "# 3. Ejecutar\n",
    "print(f\"Ejecutando: {comando}\")\n",
    "os.system(comando)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae5f7b",
   "metadata": {},
   "source": [
    "## 3. Preparaci√≥n y Partici√≥n del Dataset (Train/Val Split) \n",
    "\n",
    "Una vez etiquetadas las im√°genes, debemos organizar los datos en la estructura que YOLO necesita (`train` y `val`). En lugar de hacer una divisi√≥n aleatoria simple, aplicamos una **estrategia h√≠brida inteligente** para maximizar el aprendizaje y obtener m√©tricas honestas:\n",
    "\n",
    "1.  **Datos Reales (Frames de v√≠deo):** Se dividen aleatoriamente en **80% Entrenamiento / 20% Validaci√≥n**. Esto garantiza que el examen final del modelo (la validaci√≥n) se realice sobre im√°genes de partidas reales, que es el objetivo del proyecto.\n",
    "2.  **Datos Sint√©ticos (Capturas personalizadas):** Se env√≠an al **100% a Entrenamiento**. Estos datos sirven para que la red neuronal aprenda la morfolog√≠a de las piezas en situaciones extremas, pero no queremos validarnos con ellos porque distorsionar√≠an las m√©tricas de rendimiento real.\n",
    "\n",
    "El siguiente script automatiza la creaci√≥n de la estructura de carpetas, realiza el reparto selectivo y genera el archivo de configuraci√≥n `data.yaml` necesario para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3b8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# CONFIGURACI√ìN\n",
    "# 1. D√≥nde est√° todo mezclado ahora\n",
    "origen_dir = 'T05-T06_videos/dataset_raw'\n",
    "\n",
    "# 2. D√≥nde vamos a poner los datos ordenados\n",
    "destino_dir = 'T05-T06_videos/dataset_ready'\n",
    "\n",
    "# 3. LISTA DE CLASES\n",
    "classes_list = [\n",
    "    \"p_b\", \"p_n\", \"t_n\", \"c_n\", \"a_n\", \"d_n\", \n",
    "    \"r_n\", \"t_b\", \"c_b\", \"a_b\", \"d_b\", \"r_b\"\n",
    "]\n",
    "\n",
    "def preparar_yolo_inteligente():\n",
    "    src_images = os.path.join(origen_dir, 'images')\n",
    "    src_labels = os.path.join(origen_dir, 'labels')\n",
    "\n",
    "    # Limpieza previa del destino\n",
    "    if os.path.exists(destino_dir):\n",
    "        shutil.rmtree(destino_dir)\n",
    "    \n",
    "    # Crear carpetas vac√≠as\n",
    "    for split in ['train', 'val']:\n",
    "        os.makedirs(os.path.join(destino_dir, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(destino_dir, split, 'labels'), exist_ok=True)\n",
    "\n",
    "    # Listar todas las im√°genes\n",
    "    todas_imagenes = [f for f in os.listdir(src_images) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))]\n",
    "    \n",
    "    print(f\"üîé Analizando {len(todas_imagenes)} im√°genes en total...\")\n",
    "\n",
    "    # Listas temporales\n",
    "    datos_videos = []   # Partidas reales\n",
    "    datos_capturas = [] # Tableros personalizados\n",
    "\n",
    "    for img_file in todas_imagenes:\n",
    "        nombre_base = os.path.splitext(img_file)[0]\n",
    "        txt_file = nombre_base + \".txt\"\n",
    "        txt_path = os.path.join(src_labels, txt_file)\n",
    "\n",
    "        # Verificamos que tenga etiqueta\n",
    "        if os.path.exists(txt_path):\n",
    "            pareja = (img_file, txt_file)\n",
    "            \n",
    "            # Clasificamos seg√∫n el nombre del archivo\n",
    "            if img_file.startswith(\"Video\"):\n",
    "                datos_videos.append(pareja)\n",
    "            else:\n",
    "                # Asumimos que si no es Video, es Captura de pantalla \n",
    "                datos_capturas.append(pareja)\n",
    "    \n",
    "    print(f\"‚úÖ Detectados:\")\n",
    "    print(f\"   - {len(datos_videos)} frames de V√≠deo (Partidas Reales)\")\n",
    "    print(f\"   - {len(datos_capturas)} capturas personalizadas (Sint√©ticas)\")\n",
    "\n",
    "    # DIVISI√ìN DE DATOS\n",
    "    \n",
    "    # 1. Los Videos los mezclamos y dividimos 80/20\n",
    "    random.seed(42)\n",
    "    random.shuffle(datos_videos)\n",
    "    \n",
    "    split_idx = int(len(datos_videos) * 0.8)\n",
    "    \n",
    "    videos_train = datos_videos[:split_idx]\n",
    "    videos_val = datos_videos[split_idx:]\n",
    "    \n",
    "    # 2. Las Capturas van TODAS a train (sin mezclar ni dividir)\n",
    "    # As√≠ el train tiene variedad, pero el val examina con partidas reales\n",
    "    train_final = videos_train + datos_capturas\n",
    "    val_final = videos_val\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"üìä REPARTO FINAL:\")\n",
    "    print(f\"   TRAIN: {len(train_final)} im√°genes ({len(videos_train)} reales + {len(datos_capturas)} sint√©ticas)\")\n",
    "    print(f\"   VAL:   {len(val_final)} im√°genes (Solo reales)\")\n",
    "\n",
    "    # COPIADO\n",
    "    def copiar(lista, split):\n",
    "        print(f\"üìÇ Copiando archivos a {split}...\")\n",
    "        for img, txt in lista:\n",
    "            shutil.copy(os.path.join(src_images, img), \n",
    "                        os.path.join(destino_dir, split, 'images', img))\n",
    "            shutil.copy(os.path.join(src_labels, txt), \n",
    "                        os.path.join(destino_dir, split, 'labels', txt))\n",
    "\n",
    "    copiar(train_final, 'train')\n",
    "    copiar(val_final, 'val')\n",
    "\n",
    "    # YAML\n",
    "    yaml_content = {\n",
    "        'path': os.path.abspath(destino_dir),\n",
    "        'train': 'train/images',\n",
    "        'val': 'val/images',\n",
    "        'names': {i: name for i, name in enumerate(classes_list)}\n",
    "    }\n",
    "\n",
    "    yaml_path = os.path.join(destino_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"‚ú® ¬°Dataset listo! Configuraci√≥n guardada en: {yaml_path}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_yolo_inteligente()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4a82f",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento Preliminar: Modelo Base (YOLOv8 Nano)\n",
    "\n",
    "Para la primera iteraci√≥n del sistema, seleccionamos la arquitectura **YOLOv8n (Nano)**. Este es el modelo m√°s ligero y r√°pido de la familia YOLO, ideal para establecer una l√≠nea base de rendimiento (baseline) y verificar que el pipeline de datos funciona correctamente.\n",
    "\n",
    "Configuramos par√°metros espec√≠ficos para el contexto del ajedrez:\n",
    "* **Resoluci√≥n Alta (`imgsz=1280`):** Fundamental para distinguir piezas peque√±as (como los peones) en planos generales, ya que la resoluci√≥n est√°ndar de 640x640 suele ser insuficiente para este dominio.\n",
    "* **Aumentaci√≥n de Datos:** Activamos `mosaic` y ligeras rotaciones para que el modelo aprenda a generalizar y no dependa de una alineaci√≥n perfecta del tablero.\n",
    "\n",
    "*Nota: Este modelo sirve como prueba inicial. Posteriormente se refinar√° el entrenamiento utilizando una arquitectura m√°s compleja (Small) para mejorar la precisi√≥n en casos dif√≠ciles.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Cargar modelo nano\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# 2. Iniciar Entrenamiento\n",
    "results = model.train(\n",
    "    # Ruta al archivo yaml creado en el paso anterior\n",
    "    data='T05-T06_videos/dataset_ready/data.yaml',\n",
    "    \n",
    "    epochs=100,        # Damos 100 vueltas (se parar√° antes si deja de aprender)\n",
    "    imgsz=1280,        # Alta resoluci√≥n para ver detalles\n",
    "    batch=4,           # Batch peque√±o para no saturar memoria (si falla, baja a 2)\n",
    "    patience=20,       # Si en 20 √©pocas no mejora, paramos\n",
    "    name='ajedrez_final',\n",
    "    \n",
    "    # Ajustes extra para mejorar detecci√≥n\n",
    "    mosaic=1.0,        # Ayuda a detectar objetos peque√±os\n",
    "    degrees=5.0,       # Rotaci√≥n ligera para que aprenda tableros torcidos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b30ea",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento Avanzado: Modelo Robusto (YOLOv8 Small) \n",
    "Tras validar el flujo de trabajo con el modelo Nano, procedemos al entrenamiento del modelo final utilizando la arquitectura **YOLOv8s (Small)**. Esta versi√≥n cuenta con un mayor n√∫mero de par√°metros (11.1M frente a los 3.2M del Nano), lo que le otorga una capacidad superior para distinguir detalles sutiles, como la diferencia entre un Alfil y un Pe√≥n en posiciones complejas.\n",
    "\n",
    "### Estrategia de Aumentaci√≥n de Datos (Data Augmentation)\n",
    "Para garantizar que el sistema funcione en condiciones reales y no se vea afectado por las ayudas visuales de las plataformas (ej: casillas que se iluminan en azul o rojo al hacer una \"Jugada Brillante\"), hemos implementado una configuraci√≥n de aumentaci√≥n agresiva:\n",
    "\n",
    "* **Inmunidad al Color (HSV):** Modificamos intensamente la saturaci√≥n (`hsv_s=0.7`) y el brillo (`hsv_v=0.4`) durante el entrenamiento. Esto fuerza a la red a aprender las **formas** de las piezas en lugar de depender de sus colores exactos, haci√©ndola robusta frente a tableros de colores ex√≥ticos o cambios de iluminaci√≥n.\n",
    "* **Geometr√≠a:** Aumentamos la rotaci√≥n (`degrees=10.0`) y el escalado (`scale=0.5`) para que el detector sea invariante a la posici√≥n de la c√°mara o al zoom del navegador.\n",
    "* **Duraci√≥n:** Extendemos el entrenamiento a **120 √©pocas** con un `patience` de 25, permitiendo que el modelo converja completamente sin detenerse prematuramente ante estancamientos temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# CAMBIO 1: Cargamos el modelo \"Small\" (s)\n",
    "# Es el hermano mayor del Nano. M√°s preciso, pero requiere un poco m√°s de GPU.\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "# 2. Iniciar Entrenamiento\n",
    "results = model.train(\n",
    "    data='T05-T06_videos/dataset_ready/data.yaml',\n",
    "    \n",
    "    # Par√°metros de Entrenamiento\n",
    "    epochs=120,        # Subimos un poco las √©pocas\n",
    "    patience=25,       # M√°s paciencia\n",
    "    imgsz=1280,        # Mantenemos la alta resoluci√≥n\n",
    "    batch=4,           \n",
    "    \n",
    "    # CAMBIO 2: Nombre nuevo\n",
    "    name='ajedrez_pro_small', \n",
    "    \n",
    "    # Aumentaci√≥n de Datos (Data Augmentation)\n",
    "    # Esto crea \"alucinaciones\" durante el entrenamiento para hacerlo robusto\n",
    "    \n",
    "    mosaic=1.0,        # Mantenemos el mosaico (bueno para objetos peque√±os)\n",
    "    degrees=10.0,      # Subimos un poco la rotaci√≥n (para c√°maras movidas)\n",
    "    scale=0.5,         # Zoom in/out (para que entienda piezas cerca y lejos)\n",
    "    \n",
    "    # CAMBIO 3: Inmunidad a los colores (Jugada Brillante / Tableros Raros)\n",
    "    hsv_h=0.015,       # Cambia ligeramente el tono de color\n",
    "    hsv_s=0.7,         # Cambia MUCHO la saturaci√≥n (colores vivos vs apagados)\n",
    "    hsv_v=0.4,         # Cambia el brillo (luz vs oscuridad)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762b401",
   "metadata": {},
   "source": [
    "## 6. Configuraci√≥n del Sistema de Inferencia y L√≥gica Heur√≠stica \n",
    "\n",
    "Una vez entrenado el modelo, pasamos a la fase de **explotaci√≥n**. En este bloque definimos las constantes globales que gobernar√°n el comportamiento del sistema durante el procesamiento del v√≠deo.\n",
    "\n",
    "Cabe destacar dos par√°metros cr√≠ticos para la estabilidad del sistema:\n",
    "* **`SKIP_FRAMES = 3`:** Optimizaci√≥n de rendimiento. No procesamos cada frame individualmente (lo cual ser√≠a redundante y lento), sino uno de cada 3. Esto triplica la velocidad de procesamiento sin perder informaci√≥n relevante, ya que el ajedrez es un juego de movimientos pausados.\n",
    "* **`UMBRAL_CONFIRMACION = 5`:** Filtro de **estabilidad temporal**. Para evitar falsos positivos (por ejemplo, detectar una pieza fantasma mientras la mano del jugador cruza el tablero), el sistema exige que una nueva posici√≥n del tablero se mantenga id√©ntica durante 5 comprobaciones seguidas antes de registrar la jugada oficialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# RUTAS Y PAR√ÅMETROS \n",
    "MODEL_PATH1 = \"runs/detect/ajedrez_final/weights/best.pt\"\n",
    "MODEL_PATH = \"runs/detect/ajedrez_pro_small/weights/best.pt\"\n",
    "\n",
    "# Configuraci√≥n visual\n",
    "ANCHO_SIDEBAR = 350\n",
    "COLOR_FONDO = 50 \n",
    "SKIP_FRAMES = 3 \n",
    "# Procesamos 1 de cada 3 frames para triplicar la velocidad\n",
    "# sin perder precisi√≥n, ya que el ajedrez es lento.\n",
    "\n",
    "# PAR√ÅMETRO DE ESTABILIDAD\n",
    "# Filtro temporal: La jugada debe mantenerse estable 5 veces\n",
    "# para descartar el movimiento de la pieza.\n",
    "UMBRAL_CONFIRMACION = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b0513",
   "metadata": {},
   "source": [
    "## 7. Implementaci√≥n del N√∫cleo: L√≥gica de Juego y Motor de Renderizado\n",
    "\n",
    "En esta secci√≥n se implementa el coraz√≥n del sistema, estructurado en tres componentes principales que transforman las detecciones visuales en una narraci√≥n coherente:\n",
    "\n",
    "### 1. Clase `TableroInteligente` (Calibraci√≥n Espacial)\n",
    "Es la encargada de traducir los p√≠xeles de la imagen a coordenadas de ajedrez (a1-h8).\n",
    "* **Auto-Calibraci√≥n Segura:** Implementa un mecanismo de seguridad al inicio (`calibrar`). El sistema no define los bordes del tablero hasta que detecta **exactamente 32 piezas** de forma estable durante varios frames. Esto evita que el tablero se deforme si el v√≠deo empieza con un fundido o una transici√≥n.\n",
    "* **Mapeo Din√°mico:** Calcula las dimensiones de las casillas en funci√≥n de los extremos detectados (`min_x`, `max_x`, etc.), permitiendo que el sistema funcione independientemente del tama√±o del tablero en la pantalla.\n",
    "\n",
    "### 2. Clase `Narrador` (Motor de Reglas)\n",
    "Gestiona el estado de la partida y aplica la l√≥gica de ajedrez:\n",
    "* **Interpretaci√≥n de Movimientos:** Compara el estado actual con el anterior para deducir qu√© ha ocurrido.\n",
    "    * **Movimiento Simple:** Una pieza desaparece de A y aparece en B.\n",
    "    * **Captura:** Dos piezas desaparecen (atacante y v√≠ctima) y una aparece (atacante en destino).\n",
    "    * **Enroque:** Detecta el movimiento simult√°neo de Rey y Torre.\n",
    "    * **Coronaci√≥n:** Detecta si un Pe√≥n desaparece y aparece una pieza mayor (Dama, Torre...) en la misma jugada.\n",
    "* **Filtro de Estabilidad:** Utiliza un contador (`contador_estabilidad`) para ignorar detecciones err√°ticas o el movimiento de la mano, confirmando la jugada solo cuando el tablero se queda quieto.\n",
    "\n",
    "### 3. Procesamiento de V√≠deo y UI (`procesar_video_con_sidebar`)\n",
    "Es el bucle principal que orquesta la ejecuci√≥n:\n",
    "1.  Obtiene las detecciones de YOLO frame a frame.\n",
    "2.  Alimenta al `Narrador` con los datos.\n",
    "3.  **Visualizaci√≥n (Overlay):** Dibuja una interfaz gr√°fica avanzada sobre el v√≠deo original. Se ha dise√±ado un **panel lateral semitransparente** (sidebar) que se posiciona din√°micamente a la derecha del tablero, asegurando que la informaci√≥n (historial y estado) sea legible sin ocultar la acci√≥n del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableroInteligente:\n",
    "    def __init__(self):\n",
    "        self.min_x, self.min_y = float('inf'), float('inf')\n",
    "        self.max_x, self.max_y = float('-inf'), float('-inf')\n",
    "        self.calibrado = False\n",
    "        self.frames_validos = 0\n",
    "        self.LIMITE_CALIBRACION = 20\n",
    "        \n",
    "        # Seguridad de Inicio\n",
    "        self.MIN_PIEZAS_PARA_ACTIVAR = 32   # Exigimos el tablero completo\n",
    "        self.racha_estabilidad_inicio = 0   # Contador de frames perfectos\n",
    "        self.FRAMES_PARA_FIARSE = 3        # Frames seguidos con 32 piezas para empezar\n",
    "\n",
    "    def calibrar(self, detecciones):\n",
    "        cantidad = len(detecciones)\n",
    "        \n",
    "        # 1. Filtro de Estabilidad:\n",
    "        # Exigimos ver las 32 piezas exactas. Si falta una o hay un falso positivo,\n",
    "        # asumimos que el tablero no es fiable (transici√≥n de v√≠deo).\n",
    "        if cantidad != self.MIN_PIEZAS_PARA_ACTIVAR:\n",
    "            self.racha_estabilidad_inicio = 0\n",
    "            return False\n",
    "        \n",
    "        # Si vemos 32, sumamos confianza\n",
    "        self.racha_estabilidad_inicio += 1\n",
    "        \n",
    "        # Si a√∫n no llevamos suficientes frames estables, esperamos.\n",
    "        if self.racha_estabilidad_inicio < self.FRAMES_PARA_FIARSE:\n",
    "            return False\n",
    "\n",
    "        # A PARTIR DE AQU√ç EL TABLERO ES SEGURO\n",
    "        # Solo entramos aqu√≠ si llevamos 10 frames seguidos viendo 32 piezas\n",
    "        \n",
    "        x1s = [box[0] for box in detecciones]\n",
    "        y1s = [box[1] for box in detecciones]\n",
    "        x2s = [box[2] for box in detecciones]\n",
    "        y2s = [box[3] for box in detecciones]\n",
    "\n",
    "        self.min_x = min(self.min_x, min(x1s))\n",
    "        self.min_y = min(self.min_y, min(y1s))\n",
    "        self.max_x = max(self.max_x, max(x2s))\n",
    "        self.max_y = max(self.max_y, max(y2s))\n",
    "        \n",
    "        self.frames_validos += 1\n",
    "        if self.frames_validos > self.LIMITE_CALIBRACION:\n",
    "            self.calibrado = True\n",
    "            \n",
    "        return True # Retornamos True para indicar que estamos \"viendo\" el tablero v√°lido\n",
    "\n",
    "    def obtener_casilla(self, bbox):\n",
    "        if not self.calibrado: return None\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        ancho, alto = self.max_x - self.min_x, self.max_y - self.min_y\n",
    "        \n",
    "        if ancho == 0 or alto == 0: return None\n",
    "        \n",
    "        margen = 40\n",
    "        if (cx < self.min_x - margen or cx > self.max_x + margen or \n",
    "            cy < self.min_y - margen or cy > self.max_y + margen): return None\n",
    "\n",
    "        col = int(((cx - self.min_x) / ancho) * 8)\n",
    "        fila = int(8 - ((cy - self.min_y) / alto) * 8)\n",
    "        col = max(0, min(7, col))\n",
    "        fila = max(0, min(7, fila))\n",
    "        letras = ['a','b','c','d','e','f','g','h']\n",
    "        return f\"{letras[col]}{fila + 1}\"\n",
    "\n",
    "class Narrador:\n",
    "    def __init__(self):\n",
    "        self.tablero = TableroInteligente()\n",
    "        self.estado_anterior = {} \n",
    "        self.historial = [] \n",
    "        self.nombres = {\n",
    "            'p_b': 'Peon B', 't_b': 'Torre B', 'c_b': 'Caballo B', 'a_b': 'Alfil B', 'd_b': 'Dama B', 'r_b': 'Rey B',\n",
    "            'p_n': 'Peon N', 't_n': 'Torre N', 'c_n': 'Caballo N', 'a_n': 'Alfil N', 'd_n': 'Dama N', 'r_n': 'Rey N'\n",
    "        }\n",
    "        self.estado_sistema = \"Esperando...\"\n",
    "        \n",
    "        self.jugada_candidata = None\n",
    "        self.contador_estabilidad = 0\n",
    "\n",
    "    def procesar(self, detecciones):\n",
    "        if not self.tablero.calibrado:\n",
    "            viendo = self.tablero.calibrar(detecciones)\n",
    "            # Mostramos info de progreso\n",
    "            if seeing := self.tablero.racha_estabilidad_inicio > 0:\n",
    "                self.estado_sistema = f\"Estabilizando ({self.tablero.racha_estabilidad_inicio}/{self.tablero.FRAMES_PARA_FIARSE})...\"\n",
    "            else:\n",
    "                self.estado_sistema = \"Esperando tablero completo (32)...\"\n",
    "            \n",
    "            if self.tablero.frames_validos > 0:\n",
    "                 self.estado_sistema = \"Calibrando dimensiones...\"\n",
    "            return\n",
    "\n",
    "        estado_actual = {}\n",
    "        for box in detecciones:\n",
    "            casilla = self.tablero.obtener_casilla(box[:4])\n",
    "            if casilla: estado_actual[casilla] = box[4]\n",
    "\n",
    "        if not self.estado_anterior:\n",
    "            self.estado_anterior = estado_actual\n",
    "            self.estado_sistema = \"Partida iniciada\"\n",
    "            return\n",
    "\n",
    "        # Detecci√≥n de Cambios\n",
    "        desap = [(k, v) for k, v in self.estado_anterior.items() if k not in estado_actual]\n",
    "        apar = [(k, v) for k, v in estado_actual.items() if k not in self.estado_anterior or self.estado_anterior[k] != v]\n",
    "        \n",
    "        hay_cambio = len(desap) > 0 or len(apar) > 0\n",
    "        texto_jugada = self._interpretar_jugada(desap, apar)\n",
    "\n",
    "        # L√≥gica de Buffer\n",
    "        if hay_cambio:\n",
    "            # Creamos una firma √∫nica del cambio convirtiendo las listas a texto.\n",
    "            # Si el frame siguiente tiene la misma firma, es que el tablero est√° quieto.\n",
    "            firma_cambio = str(desap) + str(apar)\n",
    "            \n",
    "            if firma_cambio == self.jugada_candidata:\n",
    "                self.contador_estabilidad += 1\n",
    "            else:\n",
    "                # Si la firma cambia, reseteamos el an√°lisis\n",
    "                self.jugada_candidata = firma_cambio\n",
    "                self.contador_estabilidad = 1\n",
    "                self.estado_sistema = \"Analizando...\"\n",
    "            \n",
    "            if self.contador_estabilidad >= UMBRAL_CONFIRMACION:\n",
    "                if texto_jugada:\n",
    "                    self.historial.append(texto_jugada)\n",
    "                    self.estado_sistema = \"Jugando\"\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è Movimiento complejo. Actualizando estado.\")\n",
    "\n",
    "                self.estado_anterior = estado_actual \n",
    "                self.jugada_candidata = None\n",
    "                self.contador_estabilidad = 0\n",
    "        else:\n",
    "            if self.contador_estabilidad > 0:\n",
    "                self.contador_estabilidad -= 1\n",
    "\n",
    "    def _interpretar_jugada(self, desap, apar):\n",
    "        # 1. Movimiento (1 sale, 1 llega)\n",
    "        if len(desap) == 1 and len(apar) == 1:\n",
    "            orig_c, orig_p = desap[0]\n",
    "            dest_c, dest_p = apar[0]\n",
    "            \n",
    "            nombre_origen = self.nombres.get(orig_p, orig_p)\n",
    "            \n",
    "            if orig_p == dest_p:\n",
    "                return f\"{nombre_origen}: {orig_c} -> {dest_c}\"\n",
    "            \n",
    "            # Coronacion\n",
    "            elif 'p_' in orig_p: \n",
    "                nombre_nuevo = self.nombres.get(dest_p, dest_p)\n",
    "                return f\"{nombre}: {cas} -> {dest_c} ({nombre_nuevo})\"\n",
    "\n",
    "        # 2. Captura (2 salen, 1 llega)\n",
    "        elif len(desap) == 2 and len(apar) == 1:\n",
    "             dest_c, dest_p = apar[0]\n",
    "             \n",
    "             # Captura Normal\n",
    "             for cas, pza in desap:\n",
    "                 if pza == dest_p: \n",
    "                     nombre = self.nombres.get(pza, pza)\n",
    "                     return f\"{nombre}: {cas} -> {dest_c}\"\n",
    "            \n",
    "             # Captura con Promoci√≥n\n",
    "             for cas, pza in desap:\n",
    "                 if 'p_' in pza: \n",
    "                     nombre_origen = self.nombres.get(pza, pza)\n",
    "                     nombre_nuevo = self.nombres.get(dest_p, dest_p)\n",
    "                     return f\"{nombre}: {cas} -> {dest_c} ({nombre_nuevo})\"\n",
    "        \n",
    "        # 3. ENROQUES\n",
    "        elif len(desap) == 2 and len(apar) == 2:\n",
    "            for casilla, pieza in apar:\n",
    "                if pieza == 'r_b':\n",
    "                    if casilla == 'g1': return \"Enroque Corto Blanco\"\n",
    "                    if casilla == 'c1': return \"Enroque Largo Blanco\"\n",
    "                if pieza == 'r_n':\n",
    "                    if casilla == 'g8': return \"Enroque Corto Negro\"\n",
    "                    if casilla == 'c8': return \"Enroque Largo Negro\"\n",
    "            return \"Enroque\" \n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "def procesar_video_con_sidebar(VIDEO_ENTRADA, VIDEO_SALIDA):\n",
    "    print(f\"Cargando modelo: {MODEL_PATH}\")\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    cap = cv2.VideoCapture(VIDEO_ENTRADA)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error al abrir el v√≠deo: {VIDEO_ENTRADA}\")\n",
    "        return\n",
    "\n",
    "    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out_w = frame_w \n",
    "    out_h = frame_h\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(VIDEO_SALIDA, fourcc, fps, (out_w, out_h))\n",
    "\n",
    "    narrador = Narrador()\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Configuraci√≥n del panel\n",
    "    ANCHO_PANEL = 320   \n",
    "    MARGEN_TABLERO = 50 \n",
    "    \n",
    "    print(\"üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        # 1. Detecci√≥n\n",
    "        results = model.predict(frame, conf=0.5, verbose=False)\n",
    "        detecciones = []\n",
    "        for box in results[0].boxes:\n",
    "            coords = box.xyxy[0].tolist()\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            detecciones.append(coords + [label])\n",
    "\n",
    "        # 2. L√≥gica\n",
    "        if frame_count % SKIP_FRAMES == 0:\n",
    "            narrador.procesar(detecciones)\n",
    "\n",
    "        # 3. Dibujado\n",
    "        frame_pintado = results[0].plot()\n",
    "        \n",
    "        t = narrador.tablero\n",
    "        if t.calibrado:\n",
    "            # Rect√°ngulo debug\n",
    "            cv2.rectangle(frame_pintado, (int(t.min_x), int(t.min_y)), (int(t.max_x), int(t.max_y)), (255, 0, 0), 2)\n",
    "            # Posici√≥n din√°mica\n",
    "            x_panel = int(t.max_x) + MARGEN_TABLERO\n",
    "        else:\n",
    "            x_panel = frame_w - ANCHO_PANEL - 50\n",
    "\n",
    "        # Tope de seguridad\n",
    "        if x_panel + ANCHO_PANEL > frame_w:\n",
    "            x_panel = frame_w - ANCHO_PANEL\n",
    "\n",
    "        # OPACIDAD\n",
    "        overlay = frame_pintado.copy()\n",
    "        cv2.rectangle(overlay, (x_panel, 0), (x_panel + ANCHO_PANEL, frame_h), (0, 0, 0), -1)\n",
    "        \n",
    "        # 0.8 del Overlay (Negro) + 0.2 de la Imagen original = Efecto cristal oscuro\n",
    "        frame_pintado = cv2.addWeighted(overlay, 0.8, frame_pintado, 0.2, 0)\n",
    "\n",
    "        # Textos\n",
    "        x_txt = x_panel + 20\n",
    "        y_txt = 50\n",
    "        \n",
    "        cv2.putText(frame_pintado, \"HISTORIAL\", (x_txt, y_txt), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        y_txt += 35\n",
    "        \n",
    "        color_estado = (0, 255, 0) if \"Jugando\" in narrador.estado_sistema else (100, 100, 255)\n",
    "        cv2.putText(frame_pintado, f\"[{narrador.estado_sistema}]\", (x_txt, y_txt), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_estado, 1)\n",
    "        y_txt += 40\n",
    "        \n",
    "        ultimas = narrador.historial[-15:]\n",
    "        total_jugadas = len(narrador.historial)\n",
    "        offset_jugada = max(0, total_jugadas - 15)\n",
    "\n",
    "        for i, jugada in enumerate(ultimas):\n",
    "            color = (0, 255, 255) if i == len(ultimas) - 1 else (220, 220, 220)\n",
    "            numero = offset_jugada + i + 1\n",
    "            cv2.putText(frame_pintado, f\"{numero}. {jugada}\", (x_txt, y_txt), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
    "            y_txt += 30\n",
    "\n",
    "        # Mostrar ventana\n",
    "        try:\n",
    "            cv2.imshow('Narrador Chess', frame_pintado)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "                break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        out.write(frame_pintado)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"‚úÖ ¬°Terminado! Guardado en: {VIDEO_SALIDA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ecc52",
   "metadata": {},
   "source": [
    "## 8. Ejecuci√≥n y Validaci√≥n Experimental: Procesamiento por Lotes \n",
    "\n",
    "Como paso final, ponemos a prueba la robustez del sistema ejecutando el pipeline completo sobre nuestro conjunto de v√≠deos de prueba (`Video1` a `Video5`).\n",
    "\n",
    "En este bloque se realizan las llamadas secuenciales a la funci√≥n principal `procesar_video_con_sidebar`. Para cada caso:\n",
    "1.  Se carga el v√≠deo original.\n",
    "2.  El sistema se **auto-calibra** detectando el tablero inicial (esperando a las 32 piezas).\n",
    "3.  Se procesa la partida jugada a jugada, generando el historial en tiempo real.\n",
    "4.  Se exporta un nuevo archivo de v√≠deo (`partidaX.mp4`) que incluye la visualizaci√≥n de las detecciones y el **panel de narrativa superpuesto**.\n",
    "\n",
    "La ejecuci√≥n por lotes nos permite verificar que el sistema es capaz de generalizar y funcionar correctamente en diferentes partidas, manteniendo la estabilidad tanto en aperturas como en finales de juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea957184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo: runs/detect/ajedrez_pro_small/weights/best.pt\n",
      "üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚úÖ ¬°Terminado! Guardado en: T05-T06_videos/partida1.mp4\n",
      "Cargando modelo: runs/detect/ajedrez_pro_small/weights/best.pt\n",
      "üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚úÖ ¬°Terminado! Guardado en: T05-T06_videos/partida2.mp4\n",
      "Cargando modelo: runs/detect/ajedrez_pro_small/weights/best.pt\n",
      "üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚úÖ ¬°Terminado! Guardado en: T05-T06_videos/partida3.mp4\n",
      "Cargando modelo: runs/detect/ajedrez_pro_small/weights/best.pt\n",
      "üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚úÖ ¬°Terminado! Guardado en: T05-T06_videos/partida4.mp4\n",
      "Cargando modelo: runs/detect/ajedrez_pro_small/weights/best.pt\n",
      "üé¨ Procesando v√≠deo... (Pulsa 'q' para salir antes)\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚ö†Ô∏è Movimiento complejo. Actualizando estado.\n",
      "‚úÖ ¬°Terminado! Guardado en: T05-T06_videos/partida5.mp4\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la funci√≥n\n",
    "procesar_video_con_sidebar(\"T05-T06_videos/Video1.mp4\",\"T05-T06_videos/partida1.mp4\" )\n",
    "procesar_video_con_sidebar(\"T05-T06_videos/Video2.mp4\",\"T05-T06_videos/partida2.mp4\" )\n",
    "procesar_video_con_sidebar(\"T05-T06_videos/Video3.mp4\",\"T05-T06_videos/partida3.mp4\" )\n",
    "procesar_video_con_sidebar(\"T05-T06_videos/Video4.mp4\",\"T05-T06_videos/partida4.mp4\" )\n",
    "procesar_video_con_sidebar(\"T05-T06_videos/Video5.mp4\",\"T05-T06_videos/partida5.mp4\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
